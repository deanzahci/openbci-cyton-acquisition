{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "h6zBZ6PvWYZC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Linear(30*8, 30*8)\n",
        "        self.layer2 = nn.Linear(30*8, 30*4)\n",
        "        self.layer3 = nn.Linear(30*4, 30*2)\n",
        "        self.layer4 = nn.Linear(30*2, 4)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = F.relu(self.layer1(input))\n",
        "        output = F.relu(self.layer2(output))\n",
        "        output = F.relu(self.layer3(output))\n",
        "        output = F.relu(self.layer4(output))\n",
        "\n",
        "        return nn.Softmax(dim=0)(output)"
      ],
      "metadata": {
        "id": "nCsOtufiWav-"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "sp9A_30FWdeL"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "VLsDkaThWg7P"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def load_training_data(filename='training_data.txt'):\n",
        "    \"\"\"\n",
        "    Load raw training data from the text file.\n",
        "    Returns:\n",
        "        data: numpy array of shape (n_epochs, window_size, n_channels)\n",
        "        labels: numpy array of shape (n_epochs,)\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    with open(filename, 'r') as f:\n",
        "        # Skip header lines (lines starting with #)\n",
        "        for line in f:\n",
        "            if not line.startswith('#'):\n",
        "                # Parse the line\n",
        "                values = line.strip().split()\n",
        "                if not values:  # Skip empty lines\n",
        "                    continue\n",
        "\n",
        "                # First value is the label\n",
        "                label = int(values[0])\n",
        "                labels.append(label)\n",
        "\n",
        "                # Remaining values are the raw channel data\n",
        "                # Reshape into (window_size, n_channels)\n",
        "                channel_data = np.array([float(x) for x in values[1:]]).reshape(-1, 8)\n",
        "                data.append(channel_data)\n",
        "\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "def generate_random_batch(data, labels, batch_size=32, epochs_per_class=8):\n",
        "    \"\"\"\n",
        "    Generate a random batch of raw epochs with balanced class distribution.\n",
        "    The data within each batch is shuffled to prevent sequential patterns.\n",
        "\n",
        "    Args:\n",
        "        data: numpy array of shape (n_epochs, window_size, n_channels)\n",
        "        labels: numpy array of shape (n_epochs,)\n",
        "        batch_size: number of epochs in the batch (must be divisible by number of classes)\n",
        "        epochs_per_class: number of epochs to include from each class\n",
        "\n",
        "    Returns:\n",
        "        batch_data: numpy array of shape (batch_size, window_size, n_channels)\n",
        "        batch_labels: numpy array of shape (batch_size,)\n",
        "    \"\"\"\n",
        "    # Get unique classes\n",
        "    classes = np.unique(labels)\n",
        "    n_classes = len(classes)\n",
        "\n",
        "    # Ensure batch_size is divisible by number of classes\n",
        "    if batch_size % n_classes != 0:\n",
        "        raise ValueError(f\"batch_size must be divisible by number of classes ({n_classes})\")\n",
        "\n",
        "    # Initialize batch arrays\n",
        "    batch_data = []\n",
        "    batch_labels = []\n",
        "\n",
        "    # For each class, randomly select epochs_per_class samples\n",
        "    for class_label in classes:\n",
        "        # Get indices for this class\n",
        "        class_indices = np.where(labels == class_label)[0]\n",
        "\n",
        "        # Randomly select epochs_per_class samples\n",
        "        selected_indices = random.sample(list(class_indices), epochs_per_class)\n",
        "\n",
        "        # Add to batch\n",
        "        batch_data.extend(data[selected_indices])\n",
        "        batch_labels.extend([class_label] * epochs_per_class)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    batch_data = np.array(batch_data)\n",
        "    batch_labels = np.array(batch_labels)\n",
        "\n",
        "    # Create a random permutation of indices\n",
        "    indices = np.random.permutation(len(batch_data))\n",
        "\n",
        "    # Shuffle both data and labels using the same permutation\n",
        "    batch_data = batch_data[indices]\n",
        "    batch_labels = batch_labels[indices]\n",
        "\n",
        "    return batch_data, batch_labels\n",
        "\n",
        "def main():\n",
        "    # Load the training data\n",
        "    print(\"Loading raw training data...\")\n",
        "    data, labels = load_training_data()\n",
        "    print(f\"Loaded {len(data)} epochs with shape {data.shape}\")\n",
        "    print(\"Label distribution:\")\n",
        "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "    for label, count in zip(unique_labels, counts):\n",
        "        print(f\"Level {label}: {count} epochs\")\n",
        "\n",
        "    # Generate a few random batches\n",
        "    print(\"\\nGenerating random batches of raw data...\")\n",
        "    for i in range(3):\n",
        "        batch_data, batch_labels = generate_random_batch(data, labels, batch_size=32, epochs_per_class=8)\n",
        "        print(f\"\\nBatch {i+1}:\")\n",
        "        print(f\"Shape: {batch_data.shape}\")\n",
        "        print(\"Label distribution:\")\n",
        "        unique_labels, counts = np.unique(batch_labels, return_counts=True)\n",
        "        for label, count in zip(unique_labels, counts):\n",
        "            print(f\"Level {label}: {count} epochs\")\n",
        "\n",
        "        # Print some statistics about the raw data\n",
        "        print(\"\\nRaw data statistics:\")\n",
        "        print(f\"Mean: {np.mean(batch_data):.2f}\")\n",
        "        print(f\"Std: {np.std(batch_data):.2f}\")\n",
        "        print(f\"Min: {np.min(batch_data):.2f}\")\n",
        "        print(f\"Max: {np.max(batch_data):.2f}\")"
      ],
      "metadata": {
        "id": "LS1r6pNMbAwq"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the training data\n",
        "print(\"Loading raw training data...\")\n",
        "data, labels = load_training_data()\n",
        "print(np.shape(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1vQ7SwDdR4K",
        "outputId": "b80d793e-aef5-4d79-f574-53e5c2221718"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading raw training data...\n",
            "(400, 255, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehot = [[1,0,0,0],[0,1,0,0],[0,0,1,0],[1,0,0,1]]\n",
        "\n",
        "for i in range(len(data)):\n",
        "  input = torch.tensor((np.abs(np.fft.fft(data[i%4*100+i//100]))[1:31]).flatten()).float()\n",
        "  output = net(input)\n",
        "  celoss = nn.CrossEntropyLoss()\n",
        "  print(onehot[labels[i%4*100+i//100]])\n",
        "  print(onehot[labels[i%4*100+i//100]])\n",
        "  outputloss = celoss(output, torch.tensor(onehot[labels[i%4*100+i//100]]).float())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKdghycdlfDo",
        "outputId": "7c3503a2-e549-44db-c4ef-f1a9a4c30aaa"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n",
            "[1, 0, 0, 0]\n",
            "[0, 1, 0, 0]\n",
            "[0, 0, 1, 0]\n",
            "[1, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net(torch.tensor((np.abs(np.fft.fft(data[301]))[1:31]).flatten()).float())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCgh5JMIq3XJ",
        "outputId": "b3e51304-65bb-4f67-9c8f-81db85e36b77"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0., 0., 0.], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    }
  ]
}